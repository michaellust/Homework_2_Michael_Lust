{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cf3c901f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Michael Lust\n",
    "#801094861\n",
    "#Real Time AI (4106)\n",
    "#March 1, 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cd59f2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models, datasets, transforms\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c82e44bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Problem 1 Building Fully connected neural network for housing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1611aaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Problem 1 part a Using 1 hidden layer with 8 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7585f052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>area</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>stories</th>\n",
       "      <th>mainroad</th>\n",
       "      <th>guestroom</th>\n",
       "      <th>basement</th>\n",
       "      <th>hotwaterheating</th>\n",
       "      <th>airconditioning</th>\n",
       "      <th>parking</th>\n",
       "      <th>prefarea</th>\n",
       "      <th>furnishingstatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13300000</td>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12250000</td>\n",
       "      <td>8960</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12250000</td>\n",
       "      <td>9960</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>semi-furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12215000</td>\n",
       "      <td>7500</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11410000</td>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      price  area  bedrooms  bathrooms  stories mainroad guestroom basement  \\\n",
       "0  13300000  7420         4          2        3      yes        no       no   \n",
       "1  12250000  8960         4          4        4      yes        no       no   \n",
       "2  12250000  9960         3          2        2      yes        no      yes   \n",
       "3  12215000  7500         4          2        2      yes        no      yes   \n",
       "4  11410000  7420         4          1        2      yes       yes      yes   \n",
       "\n",
       "  hotwaterheating airconditioning  parking prefarea furnishingstatus  \n",
       "0              no             yes        2      yes        furnished  \n",
       "1              no             yes        3       no        furnished  \n",
       "2              no              no        2      yes   semi-furnished  \n",
       "3              no             yes        3      yes        furnished  \n",
       "4              no             yes        2       no        furnished  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.DataFrame(pd.read_csv('Housing.csv'))\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8aa904f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "545"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = len(dataset)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "325ed277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(545, 13)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ea9b1624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>stories</th>\n",
       "      <th>parking</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>13300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8960</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>12250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9960</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>12250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7500</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>12215000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11410000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   area  bedrooms  bathrooms  stories  parking     price\n",
       "0  7420         4          2        3        2  13300000\n",
       "1  8960         4          4        4        3  12250000\n",
       "2  9960         3          2        2        2  12250000\n",
       "3  7500         4          2        2        3  12215000\n",
       "4  7420         4          1        2        2  11410000"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This is taking an assumption that we are focusing on these explanatory variables from homework 1 and not all of them\n",
    "#-> that can be found in the housing.csv dataset.\n",
    "num_vars = ['area', 'bedrooms', 'bathrooms', 'stories', 'parking','price'] \n",
    "Newtrain = dataset[num_vars] \n",
    "Newtrain.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "eea36e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7420,  8960,  9960,  7500,  7420,  7500,  8580, 16200,  8100,\n",
       "        5750, 13200,  6000,  6550,  3500,  7800,  6000,  6600,  8500,\n",
       "        4600,  6420,  4320,  7155,  8050,  4560,  8800,  6540,  6000,\n",
       "        8875,  7950,  5500,  7475,  7000,  4880,  5960,  6840,  7000,\n",
       "        7482,  9000,  6000,  6000,  6550,  6360,  6480,  6000,  6000,\n",
       "        6000,  6000,  6600,  4300,  7440,  7440,  6325,  6000,  5150,\n",
       "        6000,  6000, 11440,  9000,  7680,  6000,  6000,  8880,  6240,\n",
       "        6360, 11175,  8880, 13200,  7700,  6000, 12090,  4000,  6000,\n",
       "        5020,  6600,  4040,  4260,  6420,  6500,  5700,  6000,  6000,\n",
       "        4000, 10500,  6000,  3760,  8250,  6670,  3960,  7410,  8580,\n",
       "        5000,  6750,  4800,  7200,  6000,  4100,  9000,  6400,  6600,\n",
       "        6000,  6600,  5500,  5500,  6350,  5500,  4500,  5450,  6420,\n",
       "        3240,  6615,  6600,  8372,  4300,  9620,  6800,  8000,  6900,\n",
       "        3700,  6420,  7020,  6540,  7231,  6254,  7320,  6525, 15600,\n",
       "        7160,  6500,  5500, 11460,  4800,  5828,  5200,  4800,  7000,\n",
       "        6000,  5400,  4640,  5000,  6360,  5800,  6660, 10500,  4800,\n",
       "        4700,  5000, 10500,  5500,  6360,  6600,  5136,  4400,  5400,\n",
       "        3300,  3650,  6100,  6900,  2817,  7980,  3150,  6210,  6100,\n",
       "        6600,  6825,  6710,  6450,  7800,  4600,  4260,  6540,  5500,\n",
       "       10269,  8400,  5300,  3800,  9800,  8520,  6050,  7085,  3180,\n",
       "        4500,  7200,  3410,  7980,  3000,  3000, 11410,  6100,  5720,\n",
       "        3540,  7600, 10700,  6600,  4800,  8150,  4410,  7686,  2800,\n",
       "        5948,  4200,  4520,  4095,  4120,  5400,  4770,  6300,  5800,\n",
       "        3000,  2970,  6720,  4646, 12900,  3420,  4995,  4350,  4160,\n",
       "        6040,  6862,  4815,  7000,  8100,  3420,  9166,  6321, 10240,\n",
       "        6440,  5170,  6000,  3630,  9667,  5400,  4320,  3745,  4160,\n",
       "        3880,  5680,  2870,  5010,  4510,  4000,  3840,  3760,  3640,\n",
       "        2550,  5320,  5360,  3520,  8400,  4100,  4990,  3510,  3450,\n",
       "        9860,  3520,  4510,  5885,  4000,  8250,  4040,  6360,  3162,\n",
       "        3510,  3750,  3968,  4900,  2880,  4880,  4920,  4950,  3900,\n",
       "        4500,  1905,  4075,  3500,  6450,  4032,  4400, 10360,  3400,\n",
       "        6360,  6360,  4500,  2175,  4360,  7770,  6650,  2787,  5500,\n",
       "        5040,  5850,  2610,  2953,  2747,  4410,  4000,  2325,  4600,\n",
       "        3640,  5800,  7000,  4079,  3520,  2145,  4500,  8250,  3450,\n",
       "        4840,  4080,  4046,  4632,  5985,  6060,  3600,  3680,  4040,\n",
       "        5600,  5900,  4992,  4340,  3000,  4320,  3630,  3460,  5400,\n",
       "        4500,  3460,  4100,  6480,  4500,  3960,  4050,  7260,  5500,\n",
       "        3000,  3290,  3816,  8080,  2145,  3780,  3180,  5300,  3180,\n",
       "        7152,  4080,  3850,  2015,  2176,  3350,  3150,  4820,  3420,\n",
       "        3600,  5830,  2856,  8400,  8250,  2520,  6930,  3480,  3600,\n",
       "        4040,  6020,  4050,  3584,  3120,  5450,  3630,  3630,  5640,\n",
       "        3600,  4280,  3570,  3180,  3000,  3520,  5960,  4130,  2850,\n",
       "        2275,  3520,  4500,  4000,  3150,  4500,  4500,  3640,  3850,\n",
       "        4240,  3650,  4600,  2135,  3036,  3990,  7424,  3480,  3600,\n",
       "        3640,  5900,  3120,  7350,  3512,  9500,  5880, 12944,  4900,\n",
       "        3060,  5320,  2145,  4000,  3185,  3850,  2145,  2610,  1950,\n",
       "        4040,  4785,  3450,  3640,  3500,  4960,  4120,  4750,  3720,\n",
       "        3750,  3100,  3185,  2700,  2145,  4040,  4775,  2500,  3180,\n",
       "        6060,  3480,  3792,  4040,  2145,  5880,  4500,  3930,  3640,\n",
       "        4370,  2684,  4320,  3120,  3450,  3986,  3500,  4095,  1650,\n",
       "        3450,  6750,  9000,  3069,  4500,  5495,  2398,  3000,  3850,\n",
       "        3500,  8100,  4960,  2160,  3090,  4500,  3800,  3090,  3240,\n",
       "        2835,  4600,  5076,  3750,  3630,  8050,  4352,  3000,  5850,\n",
       "        4960,  3600,  3660,  3480,  2700,  3150,  6615,  3040,  3630,\n",
       "        6000,  5400,  5200,  3300,  4350,  2640,  2650,  3960,  6800,\n",
       "        4000,  4000,  3934,  2000,  3630,  2800,  2430,  3480,  4000,\n",
       "        3185,  4000,  2910,  3600,  4400,  3600,  2880,  3180,  3000,\n",
       "        4400,  3000,  3210,  3240,  3000,  3500,  4840,  7700,  3635,\n",
       "        2475,  2787,  3264,  3640,  3180,  1836,  3970,  3970,  1950,\n",
       "        5300,  3000,  2400,  3000,  3360,  3420,  1700,  3649,  2990,\n",
       "        3000,  2400,  3620,  2910,  3850], dtype=int64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Newtrain.values[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8462cd0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>stories</th>\n",
       "      <th>parking</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.458025</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.553086</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.921053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.614815</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.921053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.462963</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.918421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.458025</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.857895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       area  bedrooms  bathrooms  stories   parking     price\n",
       "0  0.458025  0.666667       0.50     0.75  0.666667  1.000000\n",
       "1  0.553086  0.666667       1.00     1.00  1.000000  0.921053\n",
       "2  0.614815  0.500000       0.50     0.50  0.666667  0.921053\n",
       "3  0.462963  0.666667       0.50     0.50  1.000000  0.918421\n",
       "4  0.458025  0.666667       0.25     0.50  0.666667  0.857895"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Copying dataset to fix SettingWithCopyWarning: \n",
    "Newtrain_copy = Newtrain.copy()\n",
    "\n",
    "#Apply normalization to dataset to \n",
    "for column in Newtrain.columns:\n",
    "    Newtrain_copy[column] = Newtrain_copy[column]  / Newtrain_copy[column].abs().max()\n",
    "\n",
    "Newtrain_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "173d89c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(436, 6)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Splitting the Data into Training and Testing Sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#The split is 80%-20% for training and testing respectively. \n",
    "np.random.seed(0)\n",
    "Newtrain,Newtest = train_test_split(Newtrain_copy, train_size = 0.8, test_size = 0.2, random_state = 1)\n",
    "\n",
    "#Displaying training shape to verify\n",
    "Newtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "87f22045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109, 6)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Displaying test shape to verify\n",
    "Newtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "42cec068",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training set\n",
    "y_Newtrain = Newtrain.pop('price')\n",
    "x_Newtrain = Newtrain\n",
    "#Validation set\n",
    "y_Newtest = Newtest.pop('price')\n",
    "x_Newtest = Newtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d7c5c61d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([436, 5])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Labeling for model \n",
    "\n",
    "#Training\n",
    "x_T = torch.tensor(x_Newtrain.values).float()\n",
    "x_V = torch.tensor(x_Newtest.values).float()\n",
    "\n",
    "#Validation\n",
    "y_T = torch.tensor(y_Newtrain.values).float().unsqueeze(-1)\n",
    "y_V = torch.tensor(y_Newtest.values).float().unsqueeze(-1)\n",
    "\n",
    "#Verifying test split \n",
    "x_T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "05a81a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modified training loop to return Epoch and Cost Values to graph\n",
    "def training_loop(n_epochs, optimizer, model, loss_fn, x_T, x_V, y_T, y_V):\n",
    "\n",
    "    #Main training loop for both training set and validation set\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        t_p_T = model(x_T)\n",
    "        loss_T = loss_fn(t_p_T, y_T)\n",
    "        \n",
    "        t_p_V = model(x_V)\n",
    "        \n",
    "        loss_V = loss_fn(t_p_V, y_V)\n",
    "\n",
    "        #Passing optimizer and loss function\n",
    "        optimizer.zero_grad()\n",
    "        loss_T.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    #Printing out Epochs and Loss\n",
    "    if epoch == 1 or epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}, Training Loss is {loss_T.item():.4f},\"\n",
    "              f\" Validation Loss is {loss_V.item():.4f}\")\n",
    "\n",
    "    #return optimizer, loss_arr_T, loss_arr_V, n_epochs_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2502895f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (hidden_linear): Linear(in_features=5, out_features=8, bias=True)\n",
       "  (hidden_activation): Tanh()\n",
       "  (output_linear): Linear(in_features=8, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now creating hidden layer for model\n",
    "#Starting of with 1 hidden layer or linear module. 8 hidden features or nodes was chosen arbitrarily.\n",
    "#Naming each module in Sequential using OrderedDict\n",
    "from collections import OrderedDict\n",
    "\n",
    "seq_model = nn.Sequential(OrderedDict([\n",
    "            ('hidden_linear', nn.Linear(len(num_vars)-1,8)), #Hidden Layer 1\n",
    "            ('hidden_activation', nn.Tanh()),\n",
    "            ('output_linear', nn.Linear(8,1)) #Outer Layer\n",
    "]))\n",
    "seq_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "937ffbdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([8, 5]), torch.Size([8]), torch.Size([1, 8]), torch.Size([1])]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Collecting weights and biases using model.parameters()\n",
    "[param.shape for param in seq_model.parameters() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ccd849de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_linear.weight torch.Size([8, 5])\n",
      "hidden_linear.bias torch.Size([8])\n",
      "output_linear.weight torch.Size([1, 8])\n",
      "output_linear.bias torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "#Showing tensors from the optimizer\n",
    "for name, param in seq_model.named_parameters():\n",
    "    print(name, param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "51bcb320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(num_vars) #Checking length of num_vars to correctly establish linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "163e688b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_linear.weight torch.Size([8, 5])\n",
      "hidden_linear.bias torch.Size([8])\n",
      "output_linear.weight torch.Size([1, 8])\n",
      "output_linear.bias torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "#Explanatory names for submodule\n",
    "for name, param in seq_model.named_parameters():\n",
    "    print(name, param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7ad86f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.1777], requires_grad=True)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accessing particular parameters using submodules as atributes\n",
    "seq_model.output_linear.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "90515121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200, Training Loss is 0.0168, Validation Loss is 0.0216\n",
      "output tensor([[0.3859],\n",
      "        [0.4751],\n",
      "        [0.3981],\n",
      "        [0.2987],\n",
      "        [0.3203],\n",
      "        [0.3248],\n",
      "        [0.3859],\n",
      "        [0.4729],\n",
      "        [0.3214],\n",
      "        [0.3146],\n",
      "        [0.3691],\n",
      "        [0.3162],\n",
      "        [0.2937],\n",
      "        [0.3123],\n",
      "        [0.4671],\n",
      "        [0.4326],\n",
      "        [0.4495],\n",
      "        [0.3339],\n",
      "        [0.3253],\n",
      "        [0.3250],\n",
      "        [0.3706],\n",
      "        [0.3836],\n",
      "        [0.3182],\n",
      "        [0.3082],\n",
      "        [0.3773],\n",
      "        [0.4479],\n",
      "        [0.3850],\n",
      "        [0.3931],\n",
      "        [0.3429],\n",
      "        [0.2856],\n",
      "        [0.2763],\n",
      "        [0.3444],\n",
      "        [0.3090],\n",
      "        [0.3797],\n",
      "        [0.4313],\n",
      "        [0.3043],\n",
      "        [0.3203],\n",
      "        [0.3839],\n",
      "        [0.2949],\n",
      "        [0.3812],\n",
      "        [0.2969],\n",
      "        [0.3719],\n",
      "        [0.3083],\n",
      "        [0.3168],\n",
      "        [0.3834],\n",
      "        [0.3277],\n",
      "        [0.4545],\n",
      "        [0.3900],\n",
      "        [0.3207],\n",
      "        [0.3106],\n",
      "        [0.4395],\n",
      "        [0.3708],\n",
      "        [0.3244],\n",
      "        [0.3302],\n",
      "        [0.5129],\n",
      "        [0.3146],\n",
      "        [0.3047],\n",
      "        [0.3766],\n",
      "        [0.4469],\n",
      "        [0.4480],\n",
      "        [0.2755],\n",
      "        [0.4093],\n",
      "        [0.3250],\n",
      "        [0.4349],\n",
      "        [0.3295],\n",
      "        [0.3222],\n",
      "        [0.3957],\n",
      "        [0.3098],\n",
      "        [0.3135],\n",
      "        [0.3294],\n",
      "        [0.3762],\n",
      "        [0.3390],\n",
      "        [0.3401],\n",
      "        [0.3248],\n",
      "        [0.3964],\n",
      "        [0.3019],\n",
      "        [0.4453],\n",
      "        [0.4441],\n",
      "        [0.4577],\n",
      "        [0.3244],\n",
      "        [0.3180],\n",
      "        [0.2897],\n",
      "        [0.3862],\n",
      "        [0.3425],\n",
      "        [0.2781],\n",
      "        [0.3168],\n",
      "        [0.3076],\n",
      "        [0.3232],\n",
      "        [0.4534],\n",
      "        [0.4461],\n",
      "        [0.3887],\n",
      "        [0.4537],\n",
      "        [0.3242],\n",
      "        [0.4119],\n",
      "        [0.3300],\n",
      "        [0.3143],\n",
      "        [0.4732],\n",
      "        [0.3960],\n",
      "        [0.4109],\n",
      "        [0.4418],\n",
      "        [0.3258],\n",
      "        [0.4156],\n",
      "        [0.3080],\n",
      "        [0.3111],\n",
      "        [0.3114],\n",
      "        [0.2730],\n",
      "        [0.4198],\n",
      "        [0.4016],\n",
      "        [0.3370]], grad_fn=<AddmmBackward0>)\n",
      "answer tensor([[0.5316],\n",
      "        [0.3421],\n",
      "        [0.4211],\n",
      "        [0.4605],\n",
      "        [0.2211],\n",
      "        [0.2842],\n",
      "        [0.1842],\n",
      "        [0.5632],\n",
      "        [0.2211],\n",
      "        [0.4842],\n",
      "        [0.2105],\n",
      "        [0.2500],\n",
      "        [0.4368],\n",
      "        [0.4474],\n",
      "        [0.5184],\n",
      "        [1.0000],\n",
      "        [0.2737],\n",
      "        [0.2158],\n",
      "        [0.4105],\n",
      "        [0.1421],\n",
      "        [0.2842],\n",
      "        [0.4211],\n",
      "        [0.2000],\n",
      "        [0.2737],\n",
      "        [0.1947],\n",
      "        [0.3947],\n",
      "        [0.1842],\n",
      "        [0.5211],\n",
      "        [0.7368],\n",
      "        [0.2579],\n",
      "        [0.5895],\n",
      "        [0.4474],\n",
      "        [0.2579],\n",
      "        [0.2211],\n",
      "        [0.4579],\n",
      "        [0.3474],\n",
      "        [0.3416],\n",
      "        [0.2421],\n",
      "        [0.4368],\n",
      "        [0.3579],\n",
      "        [0.2526],\n",
      "        [0.2211],\n",
      "        [0.1842],\n",
      "        [0.3295],\n",
      "        [0.6105],\n",
      "        [0.3658],\n",
      "        [0.3158],\n",
      "        [0.3158],\n",
      "        [0.2474],\n",
      "        [0.2342],\n",
      "        [0.3921],\n",
      "        [0.3363],\n",
      "        [0.2342],\n",
      "        [0.3053],\n",
      "        [0.3574],\n",
      "        [0.3474],\n",
      "        [0.2226],\n",
      "        [0.3311],\n",
      "        [0.3421],\n",
      "        [0.2947],\n",
      "        [0.4342],\n",
      "        [0.6316],\n",
      "        [0.2684],\n",
      "        [0.3132],\n",
      "        [0.3474],\n",
      "        [0.1958],\n",
      "        [0.3100],\n",
      "        [0.1579],\n",
      "        [0.1789],\n",
      "        [0.3632],\n",
      "        [0.2553],\n",
      "        [0.3789],\n",
      "        [0.3947],\n",
      "        [0.1947],\n",
      "        [0.5158],\n",
      "        [0.2895],\n",
      "        [0.1368],\n",
      "        [0.8579],\n",
      "        [0.4474],\n",
      "        [0.2816],\n",
      "        [0.2737],\n",
      "        [0.3395],\n",
      "        [0.6658],\n",
      "        [0.4047],\n",
      "        [0.4105],\n",
      "        [0.3000],\n",
      "        [0.3842],\n",
      "        [0.1737],\n",
      "        [0.5000],\n",
      "        [0.2732],\n",
      "        [0.2500],\n",
      "        [0.3158],\n",
      "        [0.2000],\n",
      "        [0.5789],\n",
      "        [0.2211],\n",
      "        [0.3947],\n",
      "        [0.8158],\n",
      "        [0.2474],\n",
      "        [0.4211],\n",
      "        [0.2684],\n",
      "        [0.2895],\n",
      "        [0.6737],\n",
      "        [0.2784],\n",
      "        [0.2632],\n",
      "        [0.3684],\n",
      "        [0.4816],\n",
      "        [0.5211],\n",
      "        [0.3211],\n",
      "        [0.3842]])\n",
      "hidden tensor([[ 3.0586e-03,  2.6113e-03,  3.9449e-03,  7.2785e-03,  7.7819e-05],\n",
      "        [-8.3948e-04, -6.5935e-04, -1.1299e-03, -2.0445e-03,  7.2017e-05],\n",
      "        [-4.6414e-04, -3.4188e-04, -5.9024e-04, -1.1251e-03,  5.9424e-05],\n",
      "        [-1.0942e-03, -8.3920e-04, -1.4686e-03, -2.6524e-03,  1.5419e-04],\n",
      "        [-3.5273e-03, -2.6875e-03, -4.7123e-03, -8.4770e-03,  4.4904e-04],\n",
      "        [-6.4737e-04,  2.4008e-04, -1.1563e-03, -2.5607e-03,  1.3021e-03],\n",
      "        [-1.0624e-03, -7.5822e-04, -1.4328e-03, -2.6332e-03,  3.2860e-04],\n",
      "        [-1.6753e-03, -1.2264e-03, -2.4254e-03, -4.4137e-03,  4.8296e-04]])\n"
     ]
    }
   ],
   "source": [
    "#Now testing neural network with a learing rate at 0.001 with hidden features and 1 layer\n",
    "optimizer = optim.SGD(seq_model.parameters(), lr = 1e-2)\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 200,\n",
    "    optimizer = optimizer,\n",
    "    model = seq_model,\n",
    "    loss_fn = nn.MSELoss(), #This replaces the loss function from earlier\n",
    "    x_T = x_T,\n",
    "    x_V = x_V,\n",
    "    y_T = y_T,\n",
    "    y_V = y_V,\n",
    "    )\n",
    "\n",
    "print('output', seq_model(x_V))\n",
    "print('answer', y_V)\n",
    "print('hidden', seq_model.hidden_linear.weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9ed7e469",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Problem 1 Part b Expanding network with 2 more additional layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6dd2275d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (hidden_linear): Linear(in_features=5, out_features=2, bias=True)\n",
       "  (hidden_activation): Tanh()\n",
       "  (output_linear): Linear(in_features=2, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_model_2 = nn.Sequential(OrderedDict([\n",
    "            ('hidden_linear', nn.Linear(len(num_vars)-1,8)), #Hidden Layer 1\n",
    "            ('hidden_activation', nn.Tanh()),\n",
    "            ('hidden_linear', nn.Linear(8,5)), #Hidden Layer 2\n",
    "            ('hidden_activation', nn.Tanh()),\n",
    "            ('hidden_linear', nn.Linear(5,2)), #Hidden Layer 3 \n",
    "            ('hidden_activation', nn.Tanh()),\n",
    "            ('output_linear', nn.Linear(2,1)) #Outer Layer\n",
    "]))\n",
    "seq_model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "612fdece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200, Training Loss is 0.0183, Validation Loss is 0.0234\n",
      "output tensor([[0.3908],\n",
      "        [0.3592],\n",
      "        [0.3842],\n",
      "        [0.3976],\n",
      "        [0.3787],\n",
      "        [0.3413],\n",
      "        [0.3143],\n",
      "        [0.3389],\n",
      "        [0.3427],\n",
      "        [0.3812],\n",
      "        [0.3576],\n",
      "        [0.4040],\n",
      "        [0.4002],\n",
      "        [0.4057],\n",
      "        [0.3193],\n",
      "        [0.3811],\n",
      "        [0.2855],\n",
      "        [0.3375],\n",
      "        [0.4172],\n",
      "        [0.3412],\n",
      "        [0.3335],\n",
      "        [0.3693],\n",
      "        [0.4161],\n",
      "        [0.3841],\n",
      "        [0.3493],\n",
      "        [0.3229],\n",
      "        [0.3147],\n",
      "        [0.3641],\n",
      "        [0.4062],\n",
      "        [0.4044],\n",
      "        [0.4315],\n",
      "        [0.4050],\n",
      "        [0.4024],\n",
      "        [0.3529],\n",
      "        [0.3427],\n",
      "        [0.3617],\n",
      "        [0.4199],\n",
      "        [0.3152],\n",
      "        [0.3996],\n",
      "        [0.3522],\n",
      "        [0.4217],\n",
      "        [0.3564],\n",
      "        [0.3840],\n",
      "        [0.4037],\n",
      "        [0.3962],\n",
      "        [0.3401],\n",
      "        [0.2832],\n",
      "        [0.3125],\n",
      "        [0.3430],\n",
      "        [0.3830],\n",
      "        [0.3455],\n",
      "        [0.3569],\n",
      "        [0.3414],\n",
      "        [0.3631],\n",
      "        [0.2557],\n",
      "        [0.3812],\n",
      "        [0.3615],\n",
      "        [0.3543],\n",
      "        [0.3093],\n",
      "        [0.2862],\n",
      "        [0.4321],\n",
      "        [0.3636],\n",
      "        [0.3412],\n",
      "        [0.3285],\n",
      "        [0.3634],\n",
      "        [0.3424],\n",
      "        [0.3101],\n",
      "        [0.4068],\n",
      "        [0.4236],\n",
      "        [0.3394],\n",
      "        [0.3544],\n",
      "        [0.3596],\n",
      "        [0.4008],\n",
      "        [0.3413],\n",
      "        [0.3332],\n",
      "        [0.3628],\n",
      "        [0.2874],\n",
      "        [0.3470],\n",
      "        [0.3047],\n",
      "        [0.3415],\n",
      "        [0.3797],\n",
      "        [0.4022],\n",
      "        [0.3679],\n",
      "        [0.3761],\n",
      "        [0.4366],\n",
      "        [0.3982],\n",
      "        [0.3844],\n",
      "        [0.3419],\n",
      "        [0.3066],\n",
      "        [0.3097],\n",
      "        [0.3131],\n",
      "        [0.3064],\n",
      "        [0.3656],\n",
      "        [0.3790],\n",
      "        [0.3391],\n",
      "        [0.4048],\n",
      "        [0.3356],\n",
      "        [0.3334],\n",
      "        [0.3037],\n",
      "        [0.3664],\n",
      "        [0.3409],\n",
      "        [0.3762],\n",
      "        [0.3842],\n",
      "        [0.3828],\n",
      "        [0.3826],\n",
      "        [0.4342],\n",
      "        [0.3001],\n",
      "        [0.3075],\n",
      "        [0.3604]], grad_fn=<AddmmBackward0>)\n",
      "answer tensor([[0.5316],\n",
      "        [0.3421],\n",
      "        [0.4211],\n",
      "        [0.4605],\n",
      "        [0.2211],\n",
      "        [0.2842],\n",
      "        [0.1842],\n",
      "        [0.5632],\n",
      "        [0.2211],\n",
      "        [0.4842],\n",
      "        [0.2105],\n",
      "        [0.2500],\n",
      "        [0.4368],\n",
      "        [0.4474],\n",
      "        [0.5184],\n",
      "        [1.0000],\n",
      "        [0.2737],\n",
      "        [0.2158],\n",
      "        [0.4105],\n",
      "        [0.1421],\n",
      "        [0.2842],\n",
      "        [0.4211],\n",
      "        [0.2000],\n",
      "        [0.2737],\n",
      "        [0.1947],\n",
      "        [0.3947],\n",
      "        [0.1842],\n",
      "        [0.5211],\n",
      "        [0.7368],\n",
      "        [0.2579],\n",
      "        [0.5895],\n",
      "        [0.4474],\n",
      "        [0.2579],\n",
      "        [0.2211],\n",
      "        [0.4579],\n",
      "        [0.3474],\n",
      "        [0.3416],\n",
      "        [0.2421],\n",
      "        [0.4368],\n",
      "        [0.3579],\n",
      "        [0.2526],\n",
      "        [0.2211],\n",
      "        [0.1842],\n",
      "        [0.3295],\n",
      "        [0.6105],\n",
      "        [0.3658],\n",
      "        [0.3158],\n",
      "        [0.3158],\n",
      "        [0.2474],\n",
      "        [0.2342],\n",
      "        [0.3921],\n",
      "        [0.3363],\n",
      "        [0.2342],\n",
      "        [0.3053],\n",
      "        [0.3574],\n",
      "        [0.3474],\n",
      "        [0.2226],\n",
      "        [0.3311],\n",
      "        [0.3421],\n",
      "        [0.2947],\n",
      "        [0.4342],\n",
      "        [0.6316],\n",
      "        [0.2684],\n",
      "        [0.3132],\n",
      "        [0.3474],\n",
      "        [0.1958],\n",
      "        [0.3100],\n",
      "        [0.1579],\n",
      "        [0.1789],\n",
      "        [0.3632],\n",
      "        [0.2553],\n",
      "        [0.3789],\n",
      "        [0.3947],\n",
      "        [0.1947],\n",
      "        [0.5158],\n",
      "        [0.2895],\n",
      "        [0.1368],\n",
      "        [0.8579],\n",
      "        [0.4474],\n",
      "        [0.2816],\n",
      "        [0.2737],\n",
      "        [0.3395],\n",
      "        [0.6658],\n",
      "        [0.4047],\n",
      "        [0.4105],\n",
      "        [0.3000],\n",
      "        [0.3842],\n",
      "        [0.1737],\n",
      "        [0.5000],\n",
      "        [0.2732],\n",
      "        [0.2500],\n",
      "        [0.3158],\n",
      "        [0.2000],\n",
      "        [0.5789],\n",
      "        [0.2211],\n",
      "        [0.3947],\n",
      "        [0.8158],\n",
      "        [0.2474],\n",
      "        [0.4211],\n",
      "        [0.2684],\n",
      "        [0.2895],\n",
      "        [0.6737],\n",
      "        [0.2784],\n",
      "        [0.2632],\n",
      "        [0.3684],\n",
      "        [0.4816],\n",
      "        [0.5211],\n",
      "        [0.3211],\n",
      "        [0.3842]])\n",
      "hidden tensor([[0.0075, 0.0009, 0.0050, 0.0038, 0.0162],\n",
      "        [0.0049, 0.0003, 0.0033, 0.0024, 0.0108]])\n"
     ]
    }
   ],
   "source": [
    "#Now testing neural network with a learing rate at 0.01 with hidden features and 1 layer\n",
    "optimizer = optim.SGD(seq_model_2.parameters(), lr = 1e-2)\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 200,\n",
    "    optimizer = optimizer,\n",
    "    model = seq_model_2,\n",
    "    loss_fn = nn.MSELoss(), #This replaces the loss function from earlier\n",
    "    x_T = x_T,\n",
    "    x_V = x_V,\n",
    "    y_T = y_T,\n",
    "    y_V = y_V,\n",
    "    )\n",
    "\n",
    "print('output', seq_model_2(x_V))\n",
    "print('answer', y_V)\n",
    "print('hidden', seq_model_2.hidden_linear.weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "09e7dbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Problem 2 Creating Neural Network for all 10 features with CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a29e7f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Problem 2 Part a Using 1 hidden layer with size of 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "64d5d97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choosing the 10 classes to base model out off (using the read me file to pick classes)\n",
    "class_names = ['dolphin', 'seal', 'otter', 'shark', 'ray', 'flatfish', 'beaver', 'aquarium fish', 'trout', 'whale']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1959d1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#Dowloading CIFAR-10\n",
    "from torchvision import datasets\n",
    "data_path = 'CIFAR'\n",
    "cifar10 = datasets.CIFAR10(data_path, train = True, download = True) #Gathering training data\n",
    "cifar10_val = datasets.CIFAR10(data_path, train = False, download = True) #Gathering validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ae1d0a57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking length of CIFAR 10\n",
    "len(cifar10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d1553246",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = cifar10[99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5379149d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PIL.Image.Image image mode=RGB size=32x32 at 0x1697CDE7E20>, 1, 'seal')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img, label, class_names[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5bcc1426",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting PIL images to PyTorch using transform function\n",
    "from torchvision import transforms\n",
    "\n",
    "#Seeing available objects\n",
    "#dir(transforms) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "54eca71f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Turning PIL images to tensors\n",
    "to_tensor = transforms.ToTensor()\n",
    "img_t = to_tensor(img)\n",
    "img_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7929cede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Passing transfomr to CIFAR10\n",
    "tensor_cifar10 = datasets.CIFAR10(data_path, train = True, download = False, transform = transforms.ToTensor())\n",
    "\n",
    "img_t, _ = tensor_cifar10[99]\n",
    "type(img_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c5bac668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 32, 32]), torch.float32)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_t.shape, img_t.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "eff671b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Verifying Image output and changing CxHxW to HxWxC for matplotlib\n",
    "plt.imshow(img_t.permute(1,2,0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8faefa47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Normalizing tensor as shown in lecture 9\n",
    "transformed_cifar10 = datasets.CIFAR10(data_path, train = True, download = False, transform = transforms.Compose([\n",
    "                                       transforms.ToTensor(), \n",
    "                                       transforms.Normalize((0.4915, 0.4823, 0.4468),(0.2470, 0.2435, 0.2616))\n",
    "                                        ]))\n",
    "img_t, _ = tensor_cifar10[99]\n",
    "\n",
    "plt.imshow(img_t.permute(1,2,0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b2838bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating neural network for testing and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b4572846",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing PIL to tensor for training and validation\n",
    "cifar10_T = datasets.CIFAR10(data_path, train = True, download = False, transform = transforms.Compose([\n",
    "                                       transforms.ToTensor(), \n",
    "                                       transforms.Normalize((0.4915, 0.4823, 0.4468),(0.2470, 0.2435, 0.2616))\n",
    "                                        ]))\n",
    "cifar10_V = datasets.CIFAR10(data_path, train = False, download = False, transform = transforms.Compose([\n",
    "                                       transforms.ToTensor(), \n",
    "                                       transforms.Normalize((0.4915, 0.4823, 0.4468),(0.2470, 0.2435, 0.2616))\n",
    "                                        ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "287e97b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating subclass to include the labels in class_names\n",
    "label_map = {0: 0, 2: 1}\n",
    "\n",
    "cifar10_train = [(img, label_map[label]) for img, label in cifar10_T if label in [0,2]]\n",
    "cifar10_test = [(img, label_map[label]) for img, label in cifar10_V if label in [0,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "360ad0ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "#Setting GPU to run nn\n",
    "device = torch.device(\n",
    "    \"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d1554da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.650823\n",
      "Epoch: 1, Loss: 0.675793\n",
      "Epoch: 2, Loss: 0.362879\n",
      "Epoch: 3, Loss: 0.642081\n",
      "Epoch: 4, Loss: 0.312258\n",
      "Epoch: 5, Loss: 0.201432\n",
      "Epoch: 6, Loss: 0.256429\n",
      "Epoch: 7, Loss: 0.271766\n",
      "Epoch: 8, Loss: 0.326967\n",
      "Epoch: 9, Loss: 0.372186\n",
      "Epoch: 10, Loss: 0.470994\n",
      "Epoch: 11, Loss: 0.297508\n",
      "Epoch: 12, Loss: 0.269710\n",
      "Epoch: 13, Loss: 0.331092\n",
      "Epoch: 14, Loss: 0.338139\n",
      "Epoch: 15, Loss: 0.218790\n",
      "Epoch: 16, Loss: 0.292068\n",
      "Epoch: 17, Loss: 0.556851\n",
      "Epoch: 18, Loss: 0.467893\n",
      "Epoch: 19, Loss: 0.380591\n",
      "Epoch: 20, Loss: 0.142843\n",
      "Epoch: 21, Loss: 0.245508\n",
      "Epoch: 22, Loss: 0.393837\n",
      "Epoch: 23, Loss: 0.310784\n",
      "Epoch: 24, Loss: 0.158230\n",
      "Epoch: 25, Loss: 0.398319\n",
      "Epoch: 26, Loss: 0.139342\n",
      "Epoch: 27, Loss: 0.186165\n",
      "Epoch: 28, Loss: 0.443956\n",
      "Epoch: 29, Loss: 0.132850\n",
      "Epoch: 30, Loss: 0.068939\n",
      "Epoch: 31, Loss: 0.159090\n",
      "Epoch: 32, Loss: 0.240746\n",
      "Epoch: 33, Loss: 0.060515\n",
      "Epoch: 34, Loss: 0.160722\n",
      "Epoch: 35, Loss: 0.148073\n",
      "Epoch: 36, Loss: 0.102272\n",
      "Epoch: 37, Loss: 0.143574\n",
      "Epoch: 38, Loss: 0.135476\n",
      "Epoch: 39, Loss: 0.097659\n",
      "Epoch: 40, Loss: 0.094850\n",
      "Epoch: 41, Loss: 0.103899\n",
      "Epoch: 42, Loss: 0.059085\n",
      "Epoch: 43, Loss: 0.121684\n",
      "Epoch: 44, Loss: 0.168135\n",
      "Epoch: 45, Loss: 0.091605\n",
      "Epoch: 46, Loss: 0.094860\n",
      "Epoch: 47, Loss: 0.057525\n",
      "Epoch: 48, Loss: 0.070297\n",
      "Epoch: 49, Loss: 0.050032\n",
      "Epoch: 50, Loss: 0.077328\n",
      "Epoch: 51, Loss: 0.038961\n",
      "Epoch: 52, Loss: 0.047978\n",
      "Epoch: 53, Loss: 0.046575\n",
      "Epoch: 54, Loss: 0.038204\n",
      "Epoch: 55, Loss: 0.019226\n",
      "Epoch: 56, Loss: 0.067834\n",
      "Epoch: 57, Loss: 0.080112\n",
      "Epoch: 58, Loss: 0.036175\n",
      "Epoch: 59, Loss: 0.023425\n",
      "Epoch: 60, Loss: 0.044050\n",
      "Epoch: 61, Loss: 0.055480\n",
      "Epoch: 62, Loss: 0.027808\n",
      "Epoch: 63, Loss: 0.044418\n",
      "Epoch: 64, Loss: 0.036528\n",
      "Epoch: 65, Loss: 0.029102\n",
      "Epoch: 66, Loss: 0.033848\n",
      "Epoch: 67, Loss: 0.083774\n",
      "Epoch: 68, Loss: 0.019910\n",
      "Epoch: 69, Loss: 0.034474\n",
      "Epoch: 70, Loss: 0.088874\n",
      "Epoch: 71, Loss: 0.036603\n",
      "Epoch: 72, Loss: 0.018367\n",
      "Epoch: 73, Loss: 0.024036\n",
      "Epoch: 74, Loss: 0.033104\n",
      "Epoch: 75, Loss: 0.028966\n",
      "Epoch: 76, Loss: 0.021717\n",
      "Epoch: 77, Loss: 0.089169\n",
      "Epoch: 78, Loss: 0.049643\n",
      "Epoch: 79, Loss: 0.027822\n",
      "Epoch: 80, Loss: 0.006626\n",
      "Epoch: 81, Loss: 0.014426\n",
      "Epoch: 82, Loss: 0.057388\n",
      "Epoch: 83, Loss: 0.026508\n",
      "Epoch: 84, Loss: 0.015314\n",
      "Epoch: 85, Loss: 0.017581\n",
      "Epoch: 86, Loss: 0.018602\n",
      "Epoch: 87, Loss: 0.027437\n",
      "Epoch: 88, Loss: 0.069011\n",
      "Epoch: 89, Loss: 0.021000\n",
      "Epoch: 90, Loss: 0.010820\n",
      "Epoch: 91, Loss: 0.039402\n",
      "Epoch: 92, Loss: 0.056309\n",
      "Epoch: 93, Loss: 0.011869\n",
      "Epoch: 94, Loss: 0.015778\n",
      "Epoch: 95, Loss: 0.021736\n",
      "Epoch: 96, Loss: 0.007327\n",
      "Epoch: 97, Loss: 0.016599\n",
      "Epoch: 98, Loss: 0.005632\n",
      "Epoch: 99, Loss: 0.030510\n",
      "Epoch: 100, Loss: 0.020642\n",
      "Epoch: 101, Loss: 0.030871\n",
      "Epoch: 102, Loss: 0.008192\n",
      "Epoch: 103, Loss: 0.020634\n",
      "Epoch: 104, Loss: 0.011903\n",
      "Epoch: 105, Loss: 0.017608\n",
      "Epoch: 106, Loss: 0.013597\n",
      "Epoch: 107, Loss: 0.006796\n",
      "Epoch: 108, Loss: 0.010104\n",
      "Epoch: 109, Loss: 0.008552\n",
      "Epoch: 110, Loss: 0.005672\n",
      "Epoch: 111, Loss: 0.011434\n",
      "Epoch: 112, Loss: 0.015360\n",
      "Epoch: 113, Loss: 0.006531\n",
      "Epoch: 114, Loss: 0.010598\n",
      "Epoch: 115, Loss: 0.013263\n",
      "Epoch: 116, Loss: 0.036987\n",
      "Epoch: 117, Loss: 0.019540\n",
      "Epoch: 118, Loss: 0.009852\n",
      "Epoch: 119, Loss: 0.004993\n",
      "Epoch: 120, Loss: 0.006453\n",
      "Epoch: 121, Loss: 0.007136\n",
      "Epoch: 122, Loss: 0.005623\n",
      "Epoch: 123, Loss: 0.005546\n",
      "Epoch: 124, Loss: 0.018085\n",
      "Epoch: 125, Loss: 0.022106\n",
      "Epoch: 126, Loss: 0.004590\n",
      "Epoch: 127, Loss: 0.011568\n",
      "Epoch: 128, Loss: 0.004867\n",
      "Epoch: 129, Loss: 0.005579\n",
      "Epoch: 130, Loss: 0.014582\n",
      "Epoch: 131, Loss: 0.008190\n",
      "Epoch: 132, Loss: 0.006002\n",
      "Epoch: 133, Loss: 0.010837\n",
      "Epoch: 134, Loss: 0.006159\n",
      "Epoch: 135, Loss: 0.005478\n",
      "Epoch: 136, Loss: 0.002444\n",
      "Epoch: 137, Loss: 0.011073\n",
      "Epoch: 138, Loss: 0.018185\n",
      "Epoch: 139, Loss: 0.017750\n",
      "Epoch: 140, Loss: 0.006865\n",
      "Epoch: 141, Loss: 0.010624\n",
      "Epoch: 142, Loss: 0.001777\n",
      "Epoch: 143, Loss: 0.005762\n",
      "Epoch: 144, Loss: 0.006736\n",
      "Epoch: 145, Loss: 0.008191\n",
      "Epoch: 146, Loss: 0.003928\n",
      "Epoch: 147, Loss: 0.005703\n",
      "Epoch: 148, Loss: 0.006698\n",
      "Epoch: 149, Loss: 0.017691\n",
      "Epoch: 150, Loss: 0.003913\n",
      "Epoch: 151, Loss: 0.004098\n",
      "Epoch: 152, Loss: 0.009319\n",
      "Epoch: 153, Loss: 0.005403\n",
      "Epoch: 154, Loss: 0.007789\n",
      "Epoch: 155, Loss: 0.027516\n",
      "Epoch: 156, Loss: 0.013709\n",
      "Epoch: 157, Loss: 0.012210\n",
      "Epoch: 158, Loss: 0.003299\n",
      "Epoch: 159, Loss: 0.006866\n",
      "Epoch: 160, Loss: 0.002701\n",
      "Epoch: 161, Loss: 0.012111\n",
      "Epoch: 162, Loss: 0.005735\n",
      "Epoch: 163, Loss: 0.003340\n",
      "Epoch: 164, Loss: 0.007434\n",
      "Epoch: 165, Loss: 0.003678\n",
      "Epoch: 166, Loss: 0.008905\n",
      "Epoch: 167, Loss: 0.009484\n",
      "Epoch: 168, Loss: 0.001010\n",
      "Epoch: 169, Loss: 0.004103\n",
      "Epoch: 170, Loss: 0.003936\n",
      "Epoch: 171, Loss: 0.003621\n",
      "Epoch: 172, Loss: 0.003401\n",
      "Epoch: 173, Loss: 0.006140\n",
      "Epoch: 174, Loss: 0.008931\n",
      "Epoch: 175, Loss: 0.002806\n",
      "Epoch: 176, Loss: 0.010049\n",
      "Epoch: 177, Loss: 0.002822\n",
      "Epoch: 178, Loss: 0.008515\n",
      "Epoch: 179, Loss: 0.003001\n",
      "Epoch: 180, Loss: 0.003774\n",
      "Epoch: 181, Loss: 0.003122\n",
      "Epoch: 182, Loss: 0.002762\n",
      "Epoch: 183, Loss: 0.001493\n",
      "Epoch: 184, Loss: 0.002406\n",
      "Epoch: 185, Loss: 0.004738\n",
      "Epoch: 186, Loss: 0.000692\n",
      "Epoch: 187, Loss: 0.004315\n",
      "Epoch: 188, Loss: 0.005741\n",
      "Epoch: 189, Loss: 0.009496\n",
      "Epoch: 190, Loss: 0.029340\n",
      "Epoch: 191, Loss: 0.006239\n",
      "Epoch: 192, Loss: 0.009264\n",
      "Epoch: 193, Loss: 0.004733\n",
      "Epoch: 194, Loss: 0.004113\n",
      "Epoch: 195, Loss: 0.002358\n",
      "Epoch: 196, Loss: 0.001987\n",
      "Epoch: 197, Loss: 0.009506\n",
      "Epoch: 198, Loss: 0.002751\n",
      "Epoch: 199, Loss: 0.002188\n",
      "Epoch: 200, Loss: 0.004432\n"
     ]
    }
   ],
   "source": [
    "#Creating sequential model using train loader and steps in problem 1\n",
    "train_loader = torch.utils.data.DataLoader(cifar10_train, batch_size = 64, shuffle = True)\n",
    "\n",
    "model = nn.Sequential(\n",
    "            nn.Linear(3072, 512), #Hidden Layer 1\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 2), #Outer Layer\n",
    "            nn.LogSoftmax(dim = 1))\n",
    "\n",
    "#Running on GPU\n",
    "model.to(device)\n",
    "\n",
    "learning_rate = 1e-2\n",
    "optimizer = optim.SGD(model.parameters(), lr = learning_rate)\n",
    "\n",
    "loss_fn = nn.NLLLoss()\n",
    "n_epochs = 200\n",
    "\n",
    "for epoch in range(n_epochs + 1):\n",
    "    for imgs, labels in train_loader:\n",
    "        \n",
    "        imgs, labels = imgs.to(device), labels.to(device) #Used for GPU\n",
    "        batch_size = imgs.shape[0]\n",
    "        outputs = model(imgs.view(batch_size, -1))\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    #Printing out Epochs and Loss\n",
    "    print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1232551d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 1.000000\n"
     ]
    }
   ],
   "source": [
    "#Measurning accuracy of the model on the training set\n",
    "train_loader = torch.utils.data.DataLoader(cifar10_train, batch_size=64, shuffle=False)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in train_loader:\n",
    "        \n",
    "        imgs, labels = imgs.to(device), labels.to(device) #Used for GPU\n",
    "        batch_size = imgs.shape[0]\n",
    "        outputs = model(imgs.view(batch_size, -1))\n",
    "        _, predicted = torch.max(outputs, dim = 1)\n",
    "        total += labels.shape[0]\n",
    "        correct += int((predicted == labels).sum())\n",
    "        \n",
    "print(\"Training Accuracy: %f\" % (correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a826b119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.818500\n"
     ]
    }
   ],
   "source": [
    "#Measurning accuracy of the model on the validation set\n",
    "val_loader = torch.utils.data.DataLoader(cifar10_test, batch_size=64, shuffle=False)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in val_loader:\n",
    "        \n",
    "        imgs, labels = imgs.to(device), labels.to(device) #Used for GPU\n",
    "        batch_size = imgs.shape[0]\n",
    "        outputs = model(imgs.view(batch_size, -1))\n",
    "        _, predicted = torch.max(outputs, dim = 1)\n",
    "        total += labels.shape[0]\n",
    "        correct += int((predicted == labels).sum())\n",
    "        \n",
    "print(\"Validation Accuracy: %f\" % (correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8d177b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Problem 2 part b Increasing network to two more additional layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "17c99edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.808205\n",
      "Epoch: 1, Loss: 0.746141\n",
      "Epoch: 2, Loss: 0.695775\n",
      "Epoch: 3, Loss: 0.661856\n",
      "Epoch: 4, Loss: 0.637378\n",
      "Epoch: 5, Loss: 0.616048\n",
      "Epoch: 6, Loss: 0.594556\n",
      "Epoch: 7, Loss: 0.571575\n",
      "Epoch: 8, Loss: 0.546767\n",
      "Epoch: 9, Loss: 0.520249\n",
      "Epoch: 10, Loss: 0.492521\n",
      "Epoch: 11, Loss: 0.464280\n",
      "Epoch: 12, Loss: 0.436084\n",
      "Epoch: 13, Loss: 0.408227\n",
      "Epoch: 14, Loss: 0.380753\n",
      "Epoch: 15, Loss: 0.353507\n",
      "Epoch: 16, Loss: 0.326245\n",
      "Epoch: 17, Loss: 0.298848\n",
      "Epoch: 18, Loss: 0.271509\n",
      "Epoch: 19, Loss: 0.244667\n",
      "Epoch: 20, Loss: 0.218782\n",
      "Epoch: 21, Loss: 0.194255\n",
      "Epoch: 22, Loss: 0.171452\n",
      "Epoch: 23, Loss: 0.150665\n",
      "Epoch: 24, Loss: 0.132020\n",
      "Epoch: 25, Loss: 0.115464\n",
      "Epoch: 26, Loss: 0.100821\n",
      "Epoch: 27, Loss: 0.087903\n",
      "Epoch: 28, Loss: 0.076581\n",
      "Epoch: 29, Loss: 0.063116\n",
      "Epoch: 30, Loss: 0.063395\n",
      "Epoch: 31, Loss: 0.055154\n",
      "Epoch: 32, Loss: 0.051877\n",
      "Epoch: 33, Loss: 0.049238\n",
      "Epoch: 34, Loss: 0.034733\n",
      "Epoch: 35, Loss: 0.035581\n",
      "Epoch: 36, Loss: 0.088610\n",
      "Epoch: 37, Loss: 0.037688\n",
      "Epoch: 38, Loss: 0.012919\n",
      "Epoch: 39, Loss: 0.024190\n",
      "Epoch: 40, Loss: 0.026123\n",
      "Epoch: 41, Loss: 0.022163\n",
      "Epoch: 42, Loss: 0.016217\n",
      "Epoch: 43, Loss: 0.009869\n",
      "Epoch: 44, Loss: 0.007752\n",
      "Epoch: 45, Loss: 0.010934\n",
      "Epoch: 46, Loss: 0.017326\n",
      "Epoch: 47, Loss: 0.016237\n",
      "Epoch: 48, Loss: 0.008305\n",
      "Epoch: 49, Loss: 0.009423\n",
      "Epoch: 50, Loss: 0.017738\n",
      "Epoch: 51, Loss: 0.008705\n",
      "Epoch: 52, Loss: 0.008032\n",
      "Epoch: 53, Loss: 0.004420\n",
      "Epoch: 54, Loss: 0.003317\n",
      "Epoch: 55, Loss: 0.002629\n",
      "Epoch: 56, Loss: 0.398926\n",
      "Epoch: 57, Loss: 0.004891\n",
      "Epoch: 58, Loss: 0.003045\n",
      "Epoch: 59, Loss: 0.001631\n",
      "Epoch: 60, Loss: 0.001470\n",
      "Epoch: 61, Loss: 0.000926\n",
      "Epoch: 62, Loss: 0.000806\n",
      "Epoch: 63, Loss: 0.001387\n",
      "Epoch: 64, Loss: 0.001060\n",
      "Epoch: 65, Loss: 0.000784\n",
      "Epoch: 66, Loss: 0.000618\n",
      "Epoch: 67, Loss: 0.000505\n",
      "Epoch: 68, Loss: 0.000416\n",
      "Epoch: 69, Loss: 0.000346\n",
      "Epoch: 70, Loss: 0.000326\n",
      "Epoch: 71, Loss: 0.000252\n",
      "Epoch: 72, Loss: 0.000214\n",
      "Epoch: 73, Loss: 0.000186\n",
      "Epoch: 74, Loss: 0.000166\n",
      "Epoch: 75, Loss: 0.000161\n",
      "Epoch: 76, Loss: 0.000126\n",
      "Epoch: 77, Loss: 0.000128\n",
      "Epoch: 78, Loss: 0.017897\n",
      "Epoch: 79, Loss: 0.000460\n",
      "Epoch: 80, Loss: 0.000348\n",
      "Epoch: 81, Loss: 0.000244\n",
      "Epoch: 82, Loss: 0.000192\n",
      "Epoch: 83, Loss: 0.000162\n",
      "Epoch: 84, Loss: 0.000142\n",
      "Epoch: 85, Loss: 0.000127\n",
      "Epoch: 86, Loss: 0.000115\n",
      "Epoch: 87, Loss: 0.000105\n",
      "Epoch: 88, Loss: 0.000096\n",
      "Epoch: 89, Loss: 0.000088\n",
      "Epoch: 90, Loss: 0.000081\n",
      "Epoch: 91, Loss: 0.000075\n",
      "Epoch: 92, Loss: 0.000070\n",
      "Epoch: 93, Loss: 0.000066\n",
      "Epoch: 94, Loss: 0.000062\n",
      "Epoch: 95, Loss: 0.000059\n",
      "Epoch: 96, Loss: 0.000056\n",
      "Epoch: 97, Loss: 0.000053\n",
      "Epoch: 98, Loss: 0.000051\n",
      "Epoch: 99, Loss: 0.000049\n",
      "Epoch: 100, Loss: 0.000047\n",
      "Epoch: 101, Loss: 0.000045\n",
      "Epoch: 102, Loss: 0.000043\n",
      "Epoch: 103, Loss: 0.000042\n",
      "Epoch: 104, Loss: 0.000040\n",
      "Epoch: 105, Loss: 0.000039\n",
      "Epoch: 106, Loss: 0.000038\n",
      "Epoch: 107, Loss: 0.000036\n",
      "Epoch: 108, Loss: 0.000035\n",
      "Epoch: 109, Loss: 0.000034\n",
      "Epoch: 110, Loss: 0.000033\n",
      "Epoch: 111, Loss: 0.000032\n",
      "Epoch: 112, Loss: 0.000031\n",
      "Epoch: 113, Loss: 0.000031\n",
      "Epoch: 114, Loss: 0.000030\n",
      "Epoch: 115, Loss: 0.000029\n",
      "Epoch: 116, Loss: 0.000028\n",
      "Epoch: 117, Loss: 0.000028\n",
      "Epoch: 118, Loss: 0.000027\n",
      "Epoch: 119, Loss: 0.000026\n",
      "Epoch: 120, Loss: 0.000026\n",
      "Epoch: 121, Loss: 0.000025\n",
      "Epoch: 122, Loss: 0.000025\n",
      "Epoch: 123, Loss: 0.000024\n",
      "Epoch: 124, Loss: 0.000024\n",
      "Epoch: 125, Loss: 0.000023\n",
      "Epoch: 126, Loss: 0.000023\n",
      "Epoch: 127, Loss: 0.000022\n",
      "Epoch: 128, Loss: 0.000022\n",
      "Epoch: 129, Loss: 0.000022\n",
      "Epoch: 130, Loss: 0.000021\n",
      "Epoch: 131, Loss: 0.000021\n",
      "Epoch: 132, Loss: 0.000020\n",
      "Epoch: 133, Loss: 0.000020\n",
      "Epoch: 134, Loss: 0.000020\n",
      "Epoch: 135, Loss: 0.000019\n",
      "Epoch: 136, Loss: 0.000019\n",
      "Epoch: 137, Loss: 0.000019\n",
      "Epoch: 138, Loss: 0.000018\n",
      "Epoch: 139, Loss: 0.000018\n",
      "Epoch: 140, Loss: 0.000018\n",
      "Epoch: 141, Loss: 0.000018\n",
      "Epoch: 142, Loss: 0.000017\n",
      "Epoch: 143, Loss: 0.000017\n",
      "Epoch: 144, Loss: 0.000017\n",
      "Epoch: 145, Loss: 0.000017\n",
      "Epoch: 146, Loss: 0.000016\n",
      "Epoch: 147, Loss: 0.000016\n",
      "Epoch: 148, Loss: 0.000016\n",
      "Epoch: 149, Loss: 0.000016\n",
      "Epoch: 150, Loss: 0.000016\n",
      "Epoch: 151, Loss: 0.000015\n",
      "Epoch: 152, Loss: 0.000015\n",
      "Epoch: 153, Loss: 0.000015\n",
      "Epoch: 154, Loss: 0.000015\n",
      "Epoch: 155, Loss: 0.000015\n",
      "Epoch: 156, Loss: 0.000014\n",
      "Epoch: 157, Loss: 0.000014\n",
      "Epoch: 158, Loss: 0.000014\n",
      "Epoch: 159, Loss: 0.000014\n",
      "Epoch: 160, Loss: 0.000014\n",
      "Epoch: 161, Loss: 0.000013\n",
      "Epoch: 162, Loss: 0.000013\n",
      "Epoch: 163, Loss: 0.000013\n",
      "Epoch: 164, Loss: 0.000013\n",
      "Epoch: 165, Loss: 0.000013\n",
      "Epoch: 166, Loss: 0.000013\n",
      "Epoch: 167, Loss: 0.000013\n",
      "Epoch: 168, Loss: 0.000012\n",
      "Epoch: 169, Loss: 0.000012\n",
      "Epoch: 170, Loss: 0.000012\n",
      "Epoch: 171, Loss: 0.000012\n",
      "Epoch: 172, Loss: 0.000012\n",
      "Epoch: 173, Loss: 0.000012\n",
      "Epoch: 174, Loss: 0.000012\n",
      "Epoch: 175, Loss: 0.000012\n",
      "Epoch: 176, Loss: 0.000011\n",
      "Epoch: 177, Loss: 0.000011\n",
      "Epoch: 178, Loss: 0.000011\n",
      "Epoch: 179, Loss: 0.000011\n",
      "Epoch: 180, Loss: 0.000011\n",
      "Epoch: 181, Loss: 0.000011\n",
      "Epoch: 182, Loss: 0.000011\n",
      "Epoch: 183, Loss: 0.000011\n",
      "Epoch: 184, Loss: 0.000011\n",
      "Epoch: 185, Loss: 0.000010\n",
      "Epoch: 186, Loss: 0.000010\n",
      "Epoch: 187, Loss: 0.000010\n",
      "Epoch: 188, Loss: 0.000010\n",
      "Epoch: 189, Loss: 0.000010\n",
      "Epoch: 190, Loss: 0.000010\n",
      "Epoch: 191, Loss: 0.000010\n",
      "Epoch: 192, Loss: 0.000010\n",
      "Epoch: 193, Loss: 0.000010\n",
      "Epoch: 194, Loss: 0.000010\n",
      "Epoch: 195, Loss: 0.000010\n",
      "Epoch: 196, Loss: 0.000009\n",
      "Epoch: 197, Loss: 0.000009\n",
      "Epoch: 198, Loss: 0.000009\n",
      "Epoch: 199, Loss: 0.000009\n",
      "Epoch: 200, Loss: 0.000009\n"
     ]
    }
   ],
   "source": [
    "#Increasing model complexity using intermediate layers to improve model performance\n",
    "#Dropping nn.LogSoftMax\n",
    "#The combination of nn.LogSoftmax and nn.NLLLoss is equivalent to using nn.CrossEntropyLoss.\n",
    "model2 = nn.Sequential(\n",
    "            nn.Linear(3072, 1024), #Hidden Layer 1\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(1024, 512), #Hidden Layer 2\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 128), #Hidden Layer 3\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 2)) #Outer Layer\n",
    "\n",
    "#Running on GPU\n",
    "model2.to(device)\n",
    "\n",
    "#Repeating steps for accuracy for training and validation\n",
    "learning_rate = 1e-2\n",
    "optimizer = optim.SGD(model2.parameters(), lr = learning_rate)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "n_epochs = 200\n",
    "\n",
    "for epoch in range(n_epochs + 1):\n",
    "    for imgs, labels in train_loader:\n",
    "        \n",
    "        imgs, labels = imgs.to(device), labels.to(device) #Used for GPU\n",
    "        batch_size = imgs.shape[0]\n",
    "        outputs = model2(imgs.view(batch_size, -1))\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    #Printing out Epochs and Loss\n",
    "    print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e63327e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 1.000000\n"
     ]
    }
   ],
   "source": [
    "#Measurning accuracy of the model on the training set for model2\n",
    "train_loader = torch.utils.data.DataLoader(cifar10_train, batch_size=64, shuffle=False)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in train_loader:\n",
    "        \n",
    "        imgs, labels = imgs.to(device), labels.to(device) #Used for GPU\n",
    "        batch_size = imgs.shape[0]\n",
    "        outputs = model2(imgs.view(batch_size, -1))\n",
    "        _, predicted = torch.max(outputs, dim = 1)\n",
    "        total += labels.shape[0]\n",
    "        correct += int((predicted == labels).sum())\n",
    "        \n",
    "print(\"Training Accuracy: %f\" % (correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "722d6f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.807500\n"
     ]
    }
   ],
   "source": [
    "#Measurning accuracy of the model on the validation set for model2\n",
    "val_loader = torch.utils.data.DataLoader(cifar10_test, batch_size=64, shuffle=False)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in val_loader:\n",
    "        \n",
    "        imgs, labels = imgs.to(device), labels.to(device) #Used for GPU\n",
    "        batch_size = imgs.shape[0]\n",
    "        outputs = model2(imgs.view(batch_size, -1))\n",
    "        _, predicted = torch.max(outputs, dim = 1)\n",
    "        total += labels.shape[0]\n",
    "        correct += int((predicted == labels).sum())\n",
    "        \n",
    "print(\"Training Accuracy: %f\" % (correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
